{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-28T07:34:42.924771Z",
     "start_time": "2020-01-28T07:34:39.983555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (6,6)\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "mpl.rcParams[\"image.origin\"] = 'lower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir=\"/eos/home-b/bpinolin/ML_output/\"\n",
    "plot_config=\"VBSOS\"\n",
    "cut= \"sr\"\n",
    "version = \"DNN_v7/top_WW/highZ/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(base_dir, plot_config, cut, \"samples/\", version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets  = [\"2016\",\"2017\",\"2018\"]\n",
    "samples_dirs = [os.path.join(base_dir, plot_config, cut, \"samples/\", version, p) for p in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = { 2016: 35.867, 2017: 41.5 , 2018: 59.74}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WW\n",
      "WWewk\n",
      "top\n",
      "WW\n",
      "WWewk\n",
      "top\n",
      "WW\n",
      "WWewk\n",
      "top\n"
     ]
    }
   ],
   "source": [
    "classes = { \"WWewk\": 0, \"top\":1, \"WW\":2}\n",
    "signal_name = \"WWewk\"\n",
    "sample_names = [\"WWewk\", \"top\", \"WW\"]\n",
    "\n",
    "samples = {}\n",
    "\n",
    "for samples_dir in samples_dirs:\n",
    "    for file in os.listdir(samples_dir):\n",
    "        if os.path.isdir(os.path.join(samples_dir, file)): continue\n",
    "        sname = file.split(\"_part\")[0]\n",
    "        print(sname)\n",
    "        s = pickle.load(open(os.path.join(samples_dir, file), \"rb\"))\n",
    "        s.rename(columns=lambda c: c.split(cut+\"_\")[1] if cut in c else c, inplace=True)\n",
    "        s[\"sample_name\"]= sname\n",
    "        s[\"class\"] = classes[sname]\n",
    "        if sname == signal_name:\n",
    "            s[\"signal\"] = 1\n",
    "        else: \n",
    "            s[\"signal\"] = 0\n",
    "            \n",
    "            \n",
    "        if \"2016\" in samples_dir:\n",
    "            s[\"year\"] = 2016\n",
    "            s[\"weight_\"] = s[\"weight_\"] * lumi[2016] #lumi is included \n",
    "        if \"2017\" in samples_dir:\n",
    "            s[\"year\"] = 2017\n",
    "            s[\"weight_\"] = s[\"weight_\"] * lumi[2017] #lumi is included \n",
    "        if \"2018\" in samples_dir:\n",
    "            s[\"year\"] = 2018 \n",
    "            s[\"weight_\"] = s[\"weight_\"] * lumi[2018] #lumi is included \n",
    "            \n",
    "        if sname in samples:\n",
    "            samples[sname] = pd.concat([samples[sname], s], ignore_index=True)\n",
    "        else:\n",
    "            samples[sname] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample name WW        , nsamples:       7449,   XS total: 960.0418934983124\n",
      "Sample name WWewk     , nsamples:       2630,   XS total: 87.65963632493688\n",
      "Sample name top       , nsamples:      51376,   XS total: 13342.675052833958\n"
     ]
    }
   ],
   "source": [
    "for s, df in samples.items():\n",
    "    print(f\"Sample name {s:10}, nsamples: {len(df):10},   XS total: {(df.weight_).sum():15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " _ = plt.hist(samples[\"top\"][\"weight_\"], bins=100, range=(0,0.6))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " _ = plt.hist(samples[\"WWewk\"][\"weight_\"], bins=100, range=(0,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_list = []\n",
    "bkg_names = [ name for name in sample_names if name != signal_name ]\n",
    "for bkg_name in bkg_names:\n",
    "    bkg_list.append(samples[bkg_name])\n",
    "\n",
    "background = pd.concat(bkg_list, ignore_index=True)\n",
    "\n",
    "signal = samples[\"WWewk\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization by background events"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ratio_neve_bkgsignal= len(background) / len(signal)\n",
    "\n",
    "tot_ev_weighted_bkg = (background.weight_ / background.weight_.mean()).sum()\n",
    "print(\"TOT bkg weighted events\", tot_ev_weighted_bkg)\n",
    "\n",
    "rescale_factor_sig  = (tot_ev_weighted_bkg )/ signal.weight_.sum()\n",
    "print(\"Rescale facor for signal\", rescale_factor_sig)\n",
    "\n",
    "signal[\"weight_norm\"] = signal.weight_ * rescale_factor_sig\n",
    "background[\"weight_norm\"] = background.weight_ / background.weight_.mean()\n",
    "\n",
    "print(\"Effective sig events: \", signal.weight_norm.sum())\n",
    "print(\"Effective bkg events: \", background.weight_norm.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization by signal events"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"len_sig = \", len(signal))\n",
    "print(\"len_bkg = \", len(background))\n",
    "\n",
    "ratio_neve_bkgsignal= len(background) / len(signal)\n",
    "print(\"\\nlenB/lenS = \", round(ratio_neve_bkgsignal,2))\n",
    "\n",
    "nS = signal.weight_.sum()\n",
    "nB = background.weight_.sum()\n",
    "print(\"\\nnS = \", signal.weight_.sum())\n",
    "print(\"nB = \", background.weight_.sum())\n",
    "\n",
    "rescale_factor_bkg = len(signal) / background.weight_.sum()\n",
    "print(\"\\nRescale facor for bkg\", rescale_factor_bkg)\n",
    "\n",
    "signal[\"weight_norm\"] = signal.weight_ / signal.weight_.mean()\n",
    "background[\"weight_norm\"] = background.weight_ * rescale_factor_bkg\n",
    "print(\"\\nEffective sig events: \", signal.weight_norm.sum())\n",
    "print(\"Effective bkg events: \", background.weight_norm.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What I was doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_sig =  2630\n",
      "len_bkg =  58825\n",
      "\n",
      "lenB/lenS =  22.37\n",
      "\n",
      "nS =  87\n",
      "nB =  14302\n",
      "\n",
      "Mean of signal weights:  0.9999999999999998\n",
      "Mean of bkg weights:  0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"len_sig = \", len(signal))\n",
    "print(\"len_bkg = \", len(background))\n",
    "\n",
    "ratio_neve_bkgsignal= len(background) / len(signal)\n",
    "print(\"\\nlenB/lenS = \", round(ratio_neve_bkgsignal,2))\n",
    "\n",
    "nS = signal.weight_.sum()\n",
    "nB = background.weight_.sum()\n",
    "print(\"\\nnS = \", int(nS))\n",
    "print(\"nB = \", int(nB))\n",
    "\n",
    "signal[\"weight_norm\"] = signal.weight_ / signal[\"weight_\"].mean()\n",
    "background[\"weight_norm\"] = background.weight_ * len(background)/ nB\n",
    "print(\"\\nMean of signal weights: \", signal.weight_norm.mean())\n",
    "print(\"Mean of bkg weights: \", background.weight_norm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save signal and bkg samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join(output_dir, \"for_training\"), exist_ok=True)\n",
    "pickle.dump(background, open(os.path.join(output_dir, \"for_training/background_balanced.pkl\"), \"wb\"))\n",
    "pickle.dump(signal, open(os.path.join(output_dir, \"for_training/signal_balanced.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v7 top+WW\n",
    "low_sig = 225\n",
    "low_bkg = 7155\n",
    "\n",
    "low_sig_2016 = 46\n",
    "low_bkg_2016 = 1929\n",
    "low_sig_2017 = 67\n",
    "low_bkg_2017 = 2058\n",
    "low_sig_2018 = 113\n",
    "low_bkg_2018 = 3168\n",
    "\n",
    "high_sig = 93\n",
    "high_bkg = 6063\n",
    "\n",
    "high_sig_2016 = 18\n",
    "high_bkg_2016 = 1582\n",
    "high_sig_2017 = 28\n",
    "high_bkg_2017 = 1808\n",
    "high_sig_2018 = 47\n",
    "high_bkg_2018 = 2672"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# v7 only top\n",
    "low_sig = 24035\n",
    "low_bkg = 117863\n",
    "high_sig = 9944\n",
    "high_bkg = 91882\n",
    "\n",
    "low_sig_2016 = 2257\n",
    "low_bkg_2016 = 62870\n",
    "low_sig_2017 = 11050\n",
    "low_bkg_2017 = 8435\n",
    "low_sig_2018 = 10728\n",
    "low_bkg_2018 = 46558\n",
    "\n",
    "high_sig_2016 = 901\n",
    "high_bkg_2016 = 48379\n",
    "high_sig_2017 = 4582\n",
    "high_bkg_2017 = 7306\n",
    "high_sig_2018 = 4461\n",
    "high_bkg_2018 = 36197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## v6\n",
    "\n",
    "sig_tot = 51435\n",
    "bkg_tot = 1733357\n",
    "\n",
    "print(\"Queste percentuali vengono utilizzate per la ROC della DNN\")\n",
    "print(\"% signal = \", round(len(signal)/sig_tot,3))\n",
    "print(\"% bkg = \", round(len(background)/bkg_tot,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
